{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tryout bert embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "# import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Greatly enjoyed this 1945 mystery thriller film about a young woman, Nina Foch,(Julia Ross) who is out of work and has fallen behind in her rent and is desperate to find work. Julia reads an ad in the local London newspaper looking for a secretary and rushes out to try and obtain this position. Julia obtains the position and is hired by a Mrs. Hughes, (Dame May Witty) who requires that she lives with her employer in her home and wants her to have no involvement with men friends and Julia tells them she has no family and is free to devote her entire time to this job. George Macready, (Ralph Hughes) is the son of Mrs. Hughes and has some very strange desires for playing around with knives. This was a low budget film and most of the scenes were close ups in order to avoid the expense of a background and costs for scenery. This strange family all live in a huge mansion off the Cornwall Coast of England and there is secret doors and plenty of suspense.', 1)\n"
     ]
    }
   ],
   "source": [
    "# combine both negative and pos in train and test to train\n",
    "dataSet = {}\n",
    "dataSet['train'] = []\n",
    "dataSet['test'] = []\n",
    "for p in Path('data/text_classification/train/pos/').glob('*.txt'): # 1 is pos and 0 is neg\n",
    "    entry = p.read_text(encoding='utf8')\n",
    "    dataSet['train'].append((entry, 1))\n",
    "for p in Path('data/text_classification/train/neg/').glob('*.txt'): # 1 is pos and 0 is neg\n",
    "    entry = p.read_text(encoding='utf8')\n",
    "    dataSet['train'].append((entry, 0))\n",
    "\n",
    "for p in Path('data/text_classification/test/pos/').glob('*.txt'): # 1 is pos and 0 is neg\n",
    "    entry = p.read_text(encoding='utf8')\n",
    "    dataSet['test'].append((entry, 1))\n",
    "for p in Path('data/text_classification/test/neg/').glob('*.txt'): # 1 is pos and 0 is neg\n",
    "    entry = p.read_text(encoding='utf8')\n",
    "    dataSet['test'].append((entry, 0))\n",
    "\n",
    "\n",
    "print(dataSet['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "# https://stackoverflow.com/questions/9662346/python-code-to-remove-html-tags-from-a-string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# with bert we don't need to split the sentences. But do remove the html\n",
    "cleanedTrainData = []\n",
    "CLEANHTML = re.compile('<.*?>')\n",
    "\n",
    "for entry in dataSet['train']:\n",
    "    # ! Hope the data doesn't contain heavy html tags or else it wouldn't work\n",
    "    text = re.sub(CLEANHTML, '', entry[0])\n",
    "    cleanedTrainData.append((text, entry[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greatly enjoyed this 1945 mystery thriller film about a young woman, Nina Foch,(Julia Ross) who is out of work and has fallen behind in her rent and is desperate to find work. Julia reads an ad in the local London newspaper looking for a secretary and rushes out to try and obtain this position. Julia obtains the position and is hired by a Mrs. Hughes, (Dame May Witty) who requires that she lives with her employer in her home and wants her to have no involvement with men friends and Julia tells them she has no family and is free to devote her entire time to this job. George Macready, (Ralph Hughes) is the son of Mrs. Hughes and has some very strange desires for playing around with knives. This was a low budget film and most of the scenes were close ups in order to avoid the expense of a background and costs for scenery. This strange family all live in a huge mansion off the Cornwall Coast of England and there is secret doors and plenty of suspense.\n",
      "When this movie first came out back in 1984, Prince was one of the hottest acts around. Everyone wanted to see this movie, which was not much more than a extended music video. The acting was pretty bad, but what can you expect from musicians acting on the big screen for the first time? Despite that, it was still a very entertaining film! Morris Day and Jerome Benton provide some all time classic comedy, especially their rendition of \"The Password\", which will make you think of Abbott & Costello doing their \"who's on first\" baseball routine.Appolina (who went by a single name then) provided some beautiful breasts, so you had the brief nudity covered. Plus, she is very attractive. And of course, the soundtrack of the album is one of the best Prince ever recorded. Prince later on had a fallout with Warner Bros. and changed his name, but at this particular time in his career, he was at the top of his game.This movie doesn't rank in the all time great category, but it is pretty entertaining.\n",
      "I watched the Pie-lette last night and the word that comes to mind is \"original.\" It is a word not used much in TV as they all tend to copy whatever the other network is doing and you end up with seven nights of crime shows, unfunny comedies, and reality crap.The first thing that hit me like a brick was the presence of Jim Dale. Those not familiar with the British \"Carry On ...\" series or those who have not listened to a Harry Potter book, may not be familiar with Dale. I am not sure whether his presence as narrator adds or distracts. I will have to tune in more, but it does give the show a \"Harry Potter\" atmosphere. Maybe that's a good thing.Lee Pace (Infamous, The White Countess) has a gift. It never explains where he got it, but he can bring someone back from the dead for a minute. He teams with Chi McBride (\"Boston Public,\" Roll Bounce) to solve murders using this talent. Everything is fine and funny until he comes across a childhood love, Anna Friel (Goal! The Dream Begins, Timeline) and things really get complicated. He can't send her back and he can never touch her. Boy, would that make a relationship difficult.I will be tuning in to see where this series goes in the expectation that it will continue to entertain.\n"
     ]
    }
   ],
   "source": [
    "# try print out a cleaned text\n",
    "for i in range(0, 3):\n",
    "    print(cleanedTrainData[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['using', 'a', 'transform', '##er', 'network', 'is', 'simple']\n",
      "[2478, 1037, 10938, 2121, 2897, 2003, 3722]\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "sequence = \"Using a Transformer network is simple\"\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "\n",
    "print(tokens)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Add special required formatting for BERT\n",
    "# maxSentenceLen = 0\n",
    "# for text, label in cleanedTrainData:\n",
    "#     input_ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "# \n",
    "#     maxSentenceLen = max(maxSentenceLen, len(input_ids))\n",
    "# \n",
    "# print(f'The max sentences length is: {maxSentenceLen}')\n",
    "\n",
    "# ! BERT only take 512 max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# test truncation methods [cut at the end -> shown to give better result]\n",
    "# ? https://stackoverflow.com/questions/58636587/how-to-use-bert-for-long-text-classification?noredirect=1&lq=1\n",
    "# ? https://github.com/huggingface/transformers/issues/4476#issuecomment-951445067\n",
    "def encode_right_truncated(tokenizer, text, padding='max_length', max_length=512, add_special_tokens=True):\n",
    "    out = tokenizer(text, padding=padding, max_length=max_length, add_special_tokens=add_special_tokens)\n",
    "    tokenized = out['input_ids']\n",
    "    print(f\"Length of the inputID: {len(tokenized)}, length of token type: {len(out['token_type_ids'])}, length of mask: {len(out['attention_mask'])}\")\n",
    "    print(f\"type: {out['token_type_ids']}\")\n",
    "    print(f\"type: {out['attention_mask']}\")\n",
    "    if not add_special_tokens:\n",
    "        truncated = tokenized[-max_length:]\n",
    "    else:\n",
    "        truncated = tokenized[0:1] + tokenized[-(max_length-1):]    # keep special start and end symbol\n",
    "    \n",
    "    return truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the inputID: 512, length of token type: 512, length of mask: 512\n",
      "type: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "type: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 6551, 5632, 2023, 3386, 6547, 10874, 2143, 2055, 1037, 2402, 2450, 1010, 9401, 1042, 11663, 1010, 1006, 6423, 5811, 1007, 2040, 2003, 2041, 1997, 2147, 1998, 2038, 5357, 2369, 1999, 2014, 9278, 1998, 2003, 7143, 2000, 2424, 2147, 1012, 6423, 9631, 2019, 4748, 1999, 1996, 2334, 2414, 3780, 2559, 2005, 1037, 3187, 1998, 18545, 2041, 2000, 3046, 1998, 6855, 2023, 2597, 1012, 6423, 6855, 2015, 1996, 2597, 1998, 2003, 5086, 2011, 1037, 3680, 1012, 8099, 1010, 1006, 8214, 2089, 25591, 1007, 2040, 5942, 2008, 2016, 3268, 2007, 2014, 11194, 1999, 2014, 2188, 1998, 4122, 2014, 2000, 2031, 2053, 6624, 2007, 2273, 2814, 1998, 6423, 4136, 2068, 2016, 2038, 2053, 2155, 1998, 2003, 2489, 2000, 23313, 2014, 2972, 2051, 2000, 2023, 3105, 1012, 2577, 6097, 16416, 5149, 1010, 1006, 6798, 8099, 1007, 2003, 1996, 2365, 1997, 3680, 1012, 8099, 1998, 2038, 2070, 2200, 4326, 14714, 2005, 2652, 2105, 2007, 13227, 1012, 2023, 2001, 1037, 2659, 5166, 2143, 1998, 2087, 1997, 1996, 5019, 2020, 2485, 11139, 1999, 2344, 2000, 4468, 1996, 10961, 1997, 1037, 4281, 1998, 5366, 2005, 17363, 1012, 2023, 4326, 2155, 2035, 2444, 1999, 1037, 4121, 7330, 2125, 1996, 10387, 3023, 1997, 2563, 1998, 2045, 2003, 3595, 4303, 1998, 7564, 1997, 23873, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Keeping only 512 word at the end\n",
    "count = 0\n",
    "\n",
    "for text, label in cleanedTrainData:\n",
    "    input_ids = encode_right_truncated(tokenizer, text)\n",
    "    print(input_ids)\n",
    "    break\n",
    "# print(f'The max sentences length is: {maxSentenceLen}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# unpacking\n",
    "wow = {\n",
    "    'a': 1,\n",
    "    'b': 20\n",
    "}\n",
    "\n",
    "def func (a, b):\n",
    "    print(a, b)\n",
    "\n",
    "# func(**{'a': 1, 'b': 2}, **{'c':4, 'd':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# LOOKING GOOD, now we can reuse the previous loop to create the input tensor\n",
    "\n",
    "def encode_right_truncated(tokenizer, text, padding='max_length', max_length=512, add_special_tokens=True):\n",
    "    out = tokenizer(text, padding=padding, max_length=max_length, add_special_tokens=add_special_tokens)\n",
    "    tokenized = out['input_ids']\n",
    "    tokenType = out['token_type_ids']\n",
    "    attention = out['attention_mask']\n",
    "\n",
    "    if not add_special_tokens:\n",
    "        truncated = {\n",
    "            'input_ids': tokenized[-max_length:],\n",
    "            'token_type_ids': tokenType[-max_length:],\n",
    "            'attention_mask': attention[-max_length:],\n",
    "        }\n",
    "    else:\n",
    "        truncated = {\n",
    "            'input_ids': tokenized[0:1] + tokenized[-(max_length-1):],    # keep special start and end symbol\n",
    "            'token_type_ids': tokenType[0:1] + tokenType[-(max_length-1):],\n",
    "            'attention_mask': attention[0:1] + attention[-(max_length-1):],\n",
    "        }\n",
    "    \n",
    "    return truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of inputID: torch.Size([512]) and shape of attention: torch.Size([512]) and label shape: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "testText = cleanedTrainData[0][0]\n",
    "test = encode_right_truncated(tokenizer, testText)\n",
    "\n",
    "inputIDTensor = torch.tensor(test['input_ids'])\n",
    "attentionTensor = torch.tensor(test['attention_mask'])\n",
    "labelTensor = torch.tensor(cleanedTrainData[0][1])\n",
    "\n",
    "print(f'shape of inputID: {inputIDTensor.shape} and shape of attention: {attentionTensor.shape} and label shape: {labelTensor.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input of RNN should be tensor of (batch size, max length for the whole text, dimesion of the vocab vector [the size of the vector use to represent the vocab]) \n",
    "### in Bert, the shape is (batch, 512, 768) -> 768 is the size of each vocab vector in BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out putting test_data into Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data....\n",
      "Some output: \n",
      "[('\"All the world\\'s a stage and its people actors in it\"--or something like that. Who the hell said that theatre stopped at the orchestra pit--or even at the theatre door? Why is not the audience participants in the theatrical experience, including the story itself?This film was a grand experiment that said: \"Hey! the story is you and it needs more than your attention, it needs your active participation\". \"Sometimes we bring the story to you, sometimes you have to go to the story.\"Alas no one listened, but that does not mean it should not have been said.', 1), (\"FUTZ is the only show preserved from the experimental theatre movement in New York in the 1960s (the origins of Off Off Broadway). Though it's not for everyone, it is a genuinely brilliant, darkly funny, even more often deeply disturbing tale about love, sex, personal liberty, and revenge, a serious morality tale even more relevant now in a time when Congress wants to outlaw gay marriage by trashing our Constitution. The story is not about being gay, though -- it's about love and sex that don't conform to social norms and therefore must be removed through violence and hate. On the surface, it tells the story of a man who falls in love with a pig, but like any great fable, it's not really about animals, it's about something bigger -- stifling conformity in America.The stage version won international acclaim in its original production, it toured the U.S. and Europe, and with others of its kind, influenced almost all theatre that came after it. Luckily, we have preserved here the show pretty much as it was originally conceived, with the original cast and original director, Tom O'Horgan (who also directed HAIR and Jesus Christ Superstar on Broadway).This is not a mainstream, easy-to-take, studio film -- this is an aggressive, unsettling, glorious, deeply emotional, wildly imaginative piece of storytelling that you'll never forget. And it just might change the way you see the world...\", 1)]\n"
     ]
    }
   ],
   "source": [
    "processedData = {\n",
    "    'train': [],\n",
    "    'test': []\n",
    "}\n",
    "\n",
    "# * 1 is for positive, 0 is negative\n",
    "print('loading data....')\n",
    "dataPath = 'data/test_data'\n",
    "\n",
    "for p in Path(dataPath, 'train', 'pos').glob('*.txt'):  # 1 is pos and 0 is neg\n",
    "    entry = p.read_text(encoding='utf8')\n",
    "    processedData['train'].append((entry, 1))\n",
    "for p in Path(dataPath, 'train', 'neg').glob('*.txt'):  # 1 is pos and 0 is neg\n",
    "    entry = p.read_text(encoding='utf8')\n",
    "    processedData['train'].append((entry, 0))\n",
    "\n",
    "for p in Path(dataPath, 'test', 'pos').glob('*.txt'):  # 1 is pos and 0 is neg\n",
    "    entry = p.read_text(encoding='utf8')\n",
    "    processedData['test'].append((entry, 1))\n",
    "for p in Path(dataPath, 'test', 'neg').glob('*.txt'):  # 1 is pos and 0 is neg\n",
    "    entry = p.read_text(encoding='utf8')\n",
    "    processedData['test'].append((entry, 0))\n",
    "\n",
    "# Clean the training data\n",
    "cleanedData = []\n",
    "CLEANHTML = re.compile('<.*?>')\n",
    "\n",
    "for entry in processedData['train']:\n",
    "    # ! Hope the data doesn't contain heavy html tags or else it wouldn't work\n",
    "    text = re.sub(CLEANHTML, '', entry[0])\n",
    "    cleanedData.append((text, entry[1]))\n",
    "\n",
    "\n",
    "processedData['train'] = cleanedData\n",
    "print('Some output: ')\n",
    "print(processedData['train'][0:2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Embedding is just one step to get the embedded vector before putting into the model\n",
    "Bert vector already been trained to have word related to each other to be close in their space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Testing out converting data into tensor shape\n",
    "inputData = {\n",
    "    'train': {\n",
    "        'X': [],\n",
    "        'y': []\n",
    "    },\n",
    "    'test': {\n",
    "        'X': [],\n",
    "        'y': []\n",
    "    }\n",
    "}\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "BERT_MAX_LENGTH = 512\n",
    "\n",
    "for i, (text, label) in enumerate(processedData['train']):\n",
    "    out = tokenizer(text, padding='max_length',\n",
    "                    max_length=BERT_MAX_LENGTH, add_special_tokens=True)\n",
    "    tokenized = out['input_ids']\n",
    "    tokenType = out['token_type_ids']\n",
    "    attention = out['attention_mask']\n",
    "    truncated = {\n",
    "        # keep special start and end symbol\n",
    "        'input_ids': tokenized[0:1] + tokenized[-(BERT_MAX_LENGTH-1):],\n",
    "        'token_type_ids': tokenType[0:1] + tokenType[-(BERT_MAX_LENGTH-1):],\n",
    "        'attention_mask': attention[0:1] + attention[-(BERT_MAX_LENGTH-1):],\n",
    "    }\n",
    "    inputData['train']['X'].append(truncated)\n",
    "    inputData['train']['y'].append(label)\n",
    "\n",
    "for i, (text, label) in enumerate(processedData['test']):\n",
    "    out = tokenizer(text, padding='max_length',\n",
    "                    max_length=BERT_MAX_LENGTH, add_special_tokens=True)\n",
    "    tokenized = out['input_ids']\n",
    "    tokenType = out['token_type_ids']\n",
    "    attention = out['attention_mask']\n",
    "    truncated = {\n",
    "        # keep special start and end symbol\n",
    "        'input_ids': tokenized[0:1] + tokenized[-(BERT_MAX_LENGTH-1):],\n",
    "        'token_type_ids': tokenType[0:1] + tokenType[-(BERT_MAX_LENGTH-1):],\n",
    "        'attention_mask': attention[0:1] + attention[-(BERT_MAX_LENGTH-1):],\n",
    "    }\n",
    "    inputData['test']['X'].append(truncated)\n",
    "    inputData['test']['y'].append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data len: 10, test label len: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test data len: {len(inputData['test']['X'])}, test label len: {len(inputData['test']['y'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT is trained and expect sentence pairs, so we need to number each tensor to belong to a text\n",
    "segments_ids = [x for x in range(0, len(inputData['train']['X']))]\n",
    "segments_tensor = torch.tensor(segments_ids)\n",
    "print(segments_tensor.shape)\n",
    "segments_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## Extracting embeddings\n",
    "\n",
    "# Convert inputs to pytorch tensor\n",
    "tokens_list = []\n",
    "for each in inputData['train']['X']:\n",
    "    tokens_list.append(each['input_ids'])\n",
    "tokens_tensor = torch.tensor(tokens_list)\n",
    "\n",
    "tokens_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015210151672363281,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading (…)\"pytorch_model.bin\";",
       "rate": null,
       "total": 440473133,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9575efd9d7a742c19175fff3f2657a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the BERT embedding model\n",
    "bertModel = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "bertModel.eval()    # Only wants to use the bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Wrong shape for input_ids (shape torch.Size([10, 512])) or attention_mask (shape torch.Size([10]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Now get the Bert hidden state vector (high quality) from Bert output so we can use in our own model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m     outputs \u001b[39m=\u001b[39m bertModel(tokens_tensor, segments_tensor)\n\u001b[1;32m      5\u001b[0m     hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:992\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    988\u001b[0m         token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m    990\u001b[0m \u001b[39m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[39m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m extended_attention_mask: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_extended_attention_mask(attention_mask, input_shape)\n\u001b[1;32m    994\u001b[0m \u001b[39m# If a 2D or 3D attention mask is provided for the cross-attention\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[39m# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_decoder \u001b[39mand\u001b[39;00m encoder_hidden_states \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/transformers/modeling_utils.py:828\u001b[0m, in \u001b[0;36mModuleUtilsMixin.get_extended_attention_mask\u001b[0;34m(self, attention_mask, input_shape, device, dtype)\u001b[0m\n\u001b[1;32m    826\u001b[0m         extended_attention_mask \u001b[39m=\u001b[39m attention_mask[:, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, :]\n\u001b[1;32m    827\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 828\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    829\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWrong shape for input_ids (shape \u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m) or attention_mask (shape \u001b[39m\u001b[39m{\u001b[39;00mattention_mask\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m     )\n\u001b[1;32m    832\u001b[0m \u001b[39m# Since attention_mask is 1.0 for positions we want to attend and 0.0 for\u001b[39;00m\n\u001b[1;32m    833\u001b[0m \u001b[39m# masked positions, this operation will create a tensor which is 0.0 for\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[39m# positions we want to attend and the dtype's smallest value for masked positions.\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[39m# Since we are adding it to the raw scores before the softmax, this is\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[39m# effectively the same as removing these entirely.\u001b[39;00m\n\u001b[1;32m    837\u001b[0m extended_attention_mask \u001b[39m=\u001b[39m extended_attention_mask\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mdtype)  \u001b[39m# fp16 compatibility\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong shape for input_ids (shape torch.Size([10, 512])) or attention_mask (shape torch.Size([10]))"
     ]
    }
   ],
   "source": [
    "# Now get the Bert hidden state vector (high quality) from Bert output so we can use in our own model\n",
    "with torch.no_grad():\n",
    "    outputs = bertModel(tokens_tensor, segments_tensor)\n",
    "\n",
    "    hidden_states = outputs[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
