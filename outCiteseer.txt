Loading citeseer dataset...
Unique labels [0 1 2 3 4 5]
The index train: [2993, 1795, 2953, 2020, 1513, 913, 1876, 1366, 3158, 1162, 3163, 782, 2313, 1625, 2459, 1271, 1512, 3274, 2923, 1367, 3238, 3086, 2115, 1533, 2503, 2325, 2650, 867, 423, 1101, 1311, 2216, 2557, 2323, 2476, 2106, 12, 3261, 1411, 1067, 1330, 372, 2400, 2482, 1226, 2865, 2521, 554, 34, 977, 2120, 155, 178, 227, 2947, 2577, 655, 777, 1678, 2779, 109, 2229, 855, 45, 203, 2334, 734, 146, 494, 514, 2379, 2454, 970, 339, 1020, 872, 2484, 131, 385, 2921, 1754, 2546, 3256, 97, 1694, 113, 2504, 1112, 4, 2094, 1134, 1030, 2713, 1952, 2879, 2806, 1858, 1462, 2345, 1504, 1886, 2418, 195, 381, 1739, 61, 2414, 1461, 1243, 1645, 2402, 1811, 2834, 1706, 1834, 309, 3047, 1530, 3243, 3031] and index test: [1778, 1591, 29, 3220, 1438, 693, 561, 3298, 1803, 272, 2173, 1610, 3304, 1680, 881, 1973, 1780, 1359, 3029, 3196, 1666, 1516, 1360, 83, 2477, 3040, 56, 2924, 2132, 1759, 1187, 3189, 798, 2644, 1681, 2467, 1027, 891, 2247, 1968, 823, 3067, 2623, 274, 801, 1312, 2176, 2437, 3270, 407, 2378, 1510, 3205, 862, 2170, 2917, 664, 832, 1594, 1743, 1561, 90, 3283, 884, 2081, 3308, 833, 2631, 1059, 1744, 1318, 3093, 2327, 1728, 1039, 1721, 1315, 1168, 3213, 78, 1195, 2156, 2581, 1816, 3273, 2311, 886, 1278, 1486, 2979, 2211, 2468, 1091, 3188, 1057, 2174, 2077, 2027, 1143, 1254, 831, 2560, 1697, 2130, 1370, 1408, 1145, 2183, 813, 963, 1810, 769, 130, 3072, 1627, 897, 2788, 1085, 2207, 2303, 285, 17, 3294, 1823, 2043, 2177, 1923, 1665, 191, 3103, 1082, 909, 1716, 3064, 172, 1399, 1957, 1179, 1767, 1734, 3074, 2131, 2141, 2777, 3284, 2275, 553, 3041, 474, 991, 2103, 1055, 2040, 3311, 2690, 2457, 1931, 2202, 1873, 2265, 1658, 2656, 770, 2607, 2898, 1738, 1409, 1378, 1657, 1204, 1118, 2397, 2643, 1372, 2404, 2380, 2599, 1710, 1637, 2702, 2159, 3125, 2593, 1072, 1483, 1171, 2015, 74, 2942, 175, 1342, 2527, 562, 2769, 2802, 2512, 3230, 1905, 498, 2848, 1417, 1661, 2621, 3210, 1611, 2955, 1531, 2995, 164, 1142, 2059, 2957, 3091, 1248, 2729, 1600, 2222, 1720, 1255, 2299, 2169, 1286, 2047, 2583, 2231, 2252, 2964, 2244, 3079, 1688, 2505, 2193, 3268, 512, 2714, 1690, 2733, 2201, 2937, 1984, 1911, 784, 677, 2257, 2687, 2125, 1562, 1687, 2213, 781, 2626, 2579, 1105, 1607, 1449, 2447, 1647, 128, 149, 2333, 117, 1242, 441, 1016, 1762, 2536, 352, 1775, 2900, 2661, 1088, 917, 2105, 2742, 2688, 1037, 2221, 1902, 2295, 1818, 3173, 1196, 1679, 3001, 2478, 1058, 2654, 2674, 3018, 3053, 1256, 1927, 1173, 461, 1494, 947, 2270, 518, 756, 1525, 301, 2948, 2772, 2165, 1046, 626, 1320, 1100, 120, 3077, 1466, 3171, 3141, 3272, 2861, 3299, 1632, 2971, 1990, 1176, 2609, 1362, 552, 2603, 3161, 578, 1048, 1695, 1673, 2704, 1630, 2409, 1924, 3239, 1860, 3179, 2659, 2206, 2959, 2681, 2304, 2534, 2184, 2612, 375, 1078, 2830, 1392, 1029, 1623, 1390, 2456, 1894, 1425, 1756, 2228, 2264, 2580, 1547, 1573, 2390, 1773, 1537, 3260, 73, 1146, 1639, 324, 2451, 2223, 1847, 1620, 1060, 2522, 3293, 2217, 3159, 2343, 2022, 1416, 1402, 2696, 1117, 1987, 1636, 3310, 1930, 2990, 2566, 1180, 1132, 2749, 2335, 1551, 3237, 1086, 1613, 1693, 702, 2051, 2514, 254, 952, 665, 1586, 2293, 1781, 706, 1568, 1740, 304, 1796, 576, 1022, 1284, 100, 2017, 571, 406, 922, 2460, 3115, 597, 1281, 299, 335, 275, 2361, 2767, 1231, 2427, 3129, 212, 3217, 2466, 228, 2812, 2188, 483, 122, 507, 2246, 803, 3191, 992, 2068, 3058, 234, 1806, 842, 2118, 1699, 2918, 2845, 2064, 2044, 717, 918, 1938, 539, 471, 118, 1004, 95, 800, 2706, 1283, 987, 804, 265, 2815, 233, 440, 2679, 184, 2693, 460, 3280, 967, 455, 1517, 332, 2871, 66, 1264, 748, 3015, 1290, 291, 746, 1969, 428, 51, 914, 684, 1471, 1999, 2464, 839, 1191, 2976, 883, 1247, 680, 1521, 906, 438, 2902, 366, 445, 646, 2480, 535, 1891, 2154, 1334, 1007, 2453, 2016, 3309, 640, 903, 1511, 2868, 349, 180, 408, 356, 470, 683, 1351, 2907, 342, 482, 3017, 391, 1949, 1167, 572, 7, 318, 1649, 2384, 673, 1752, 2525, 1718, 257, 1169, 3009, 419, 251, 2740, 3035, 1410, 574, 456, 1644, 2694, 904, 1199, 2473, 105, 2795, 310, 365, 2817, 1761, 1543, 1322, 608, 1197, 462, 1899, 292, 2809, 392, 1807, 1998, 2810, 2298, 1664, 812, 437, 2914, 698, 1131, 1883, 1852, 2342, 1829, 697, 420, 727, 2149, 2513, 2732, 921, 711, 799, 691, 2790, 2705, 1722, 340, 121, 1211, 651, 163, 941, 526, 3020, 989, 994, 2383, 2851, 64, 676, 3049, 42, 3203, 52, 2839, 892, 2288, 1003, 2985, 2648, 226, 663, 495, 133, 735, 2666, 3057, 973, 1032, 733, 115, 641, 529, 170, 2869, 2285, 808, 76, 2884, 2357, 99, 411, 955, 313, 312, 229, 661, 1888, 386, 2386, 1933, 125, 2646, 40, 2540, 242, 995, 2727, 373, 1024, 1126, 1770, 659, 605, 584, 861, 3033, 1287, 942, 624, 569, 1652, 1576, 368, 346, 2348, 3170, 2554, 2615, 3262, 806, 986, 314, 2984, 1233, 667, 907, 44, 114, 264, 334, 11, 247, 625, 822, 509, 854, 454, 165, 75, 500, 252, 208, 145, 1843, 2987, 1936, 2341, 488, 2996, 401, 703, 2239, 1848, 2226, 492, 1520, 2906, 1983, 84, 630, 675, 246, 347, 631, 2716, 817, 199, 426, 2920, 692, 1621, 965, 885, 2605, 351, 837, 484, 962, 2137, 656, 504, 245, 794, 92, 142, 2532, 70, 950, 3126, 496, 750, 239, 1868, 726, 650, 564, 792, 41, 3155, 20, 202, 2986, 367, 520, 721, 3104, 975, 2429, 448, 1887, 848, 847, 258, 2354, 2771, 2038, 472, 643, 434, 19, 2617, 1205, 866, 2813, 613, 511, 493, 2219, 193, 2734, 536, 912, 2635, 723, 577, 3164, 1356, 890, 1535, 644, 2284, 2191, 1746, 2410, 1992, 3065, 2825, 696, 2930, 2499, 3043, 1348, 87, 1384, 2498, 1476, 2969, 826, 329, 2637, 540, 3113, 1044, 1412, 2766, 838, 1160, 1977, 2198, 2013, 3036, 1355, 2928, 1862, 2723, 1297, 2430, 1074, 3142, 3212, 3111, 2462, 431, 2856, 2997, 2757, 2142, 1368, 948, 1577, 2186, 2811, 2545, 1193, 3184, 1559, 739, 966, 1025, 2991, 2083, 615, 1237, 283, 2365, 1386, 614, 298, 290, 2182, 2272, 1564, 36, 2697, 1560, 1379, 949, 1181, 2479, 263, 1260, 280, 916, 544, 201, 2843, 3266, 2651, 940, 985, 1431, 2143, 3157, 3139, 1859, 124, 2516, 3285, 652, 1120, 2568, 2925, 2962, 1534, 2233, 1104, 2894, 2129, 2395, 63, 2782, 2029, 1213, 1692, 2591, 2302, 2028, 294, 1757, 1729, 2653, 395, 289, 273, 3016, 8, 1514, 3105, 724, 1414, 2562, 2994, 889, 328, 2517, 3275, 3002, 330, 1459, 2807, 1415, 2318, 1400, 2331, 2144, 3241, 789, 3242, 3117, 3087, 2197, 2725, 270, 2565, 140, 627, 3066, 3198, 3076, 3061, 1913, 1800, 2563, 2622, 2973, 2551, 2448, 288, 3063, 2972, 3112, 1017, 3234, 2855, 2641, 2281, 2524, 269, 217, 3062, 134, 1981, 2989, 528, 2249, 1489, 2471, 2636, 173, 1874, 5, 3133, 2678, 2966, 2025, 2145, 2573, 2039, 3123, 2381, 2109, 2080, 3178, 1124, 1215, 2055, 2287, 1188, 1774, 1901, 1341, 1994, 1436, 1918, 2965, 1308, 1580, 3056, 565, 396, 2127, 1877, 1217, 2148, 2518, 1846, 1276, 1964, 2413, 1878, 1906, 2750, 1974, 1960, 1900, 1772, 1377, 2775, 225, 2569, 851, 1361, 1926, 3138, 1448, 2048, 1338, 2063, 413, 3039, 1423, 2863, 2739, 2859, 1785, 135, 2060, 3055, 3094, 1835, 2630, 1704, 2461, 2346, 3118, 2398, 2425, 1827, 1306, 1465, 1299, 2741, 2412, 1549, 2785, 3259, 1837, 432, 1708, 1683, 766, 1784, 2175, 2664, 1202, 1470, 2396, 3070, 1589, 1890, 3265, 2916, 1540, 818, 2836, 2121, 3032, 1831, 681, 2756, 2718, 1422, 1805, 2099, 2439, 705, 2857, 716, 2820, 207, 2336, 2072, 2828, 908, 1871, 2963, 2933, 2553, 3059, 3005, 1258, 2671, 2112, 3004, 3101, 1648, 810, 1839, 2338, 795, 1841, 926, 169, 1655, 2968, 2754, 1502, 2296, 1838, 3006, 1303, 1300, 2190, 1064, 2062, 1045, 1541, 2752, 343, 1519, 1955, 1571, 1270, 1151, 2050, 2124, 2049, 2005, 249, 1185, 1853, 2023, 1285, 3010, 1113, 433, 1446, 559, 1940, 2255, 3219, 1764, 2095, 2862, 3127, 2796, 2382, 1603, 1453, 2440, 1292, 2151, 1705, 1108, 2515, 2075, 610, 1435, 1702, 2870, 695]
method running...
--network status--
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Method_Classification                    [3312, 6]                 --
├─Sequential_8b872f: 1-1                 [3312, 6]                 --
│    └─GCNConv: 2-1                      [3312, 50]                50
│    │    └─Linear: 3-1                  [3312, 50]                185,150
│    │    └─SumAggregation: 3-2          [3312, 50]                --
│    └─ReLU: 2-2                         [3312, 50]                --
│    └─GCNConv: 2-3                      [3312, 6]                 6
│    │    └─Linear: 3-3                  [3312, 6]                 300
│    │    └─SumAggregation: 3-4          [3312, 6]                 --
│    └─Sigmoid: 2-4                      [3312, 6]                 --
==========================================================================================
Total params: 185,506
Trainable params: 185,506
Non-trainable params: 0
Total mult-adds (M): 614.21
==========================================================================================
Input size (MB): 49.13
Forward/backward pass size (MB): 1.48
Params size (MB): 0.74
Estimated Total Size (MB): 51.36
==========================================================================================
--start training...
Epoch: 0 Accuracy: 0.1503623188405797 Loss: 1.7939592599868774
Epoch: 100 Accuracy: 0.5108695652173914 Loss: 1.5636132955551147
Epoch: 200 Accuracy: 0.5733695652173914 Loss: 1.3538777828216553
Epoch: 300 Accuracy: 0.591183574879227 Loss: 1.2352451086044312
Epoch: 400 Accuracy: 0.5984299516908212 Loss: 1.1689156293869019
Epoch: 500 Accuracy: 0.5969202898550725 Loss: 1.1305650472640991
Epoch: 600 Accuracy: 0.5978260869565217 Loss: 1.1069064140319824
Epoch: 700 Accuracy: 0.5972222222222222 Loss: 1.0916157960891724
Epoch: 800 Accuracy: 0.596316425120773 Loss: 1.0811488628387451
Epoch: 900 Accuracy: 0.5948067632850241 Loss: 1.073599934577942
Epoch: 1000 Accuracy: 0.5926932367149759 Loss: 1.0679452419281006
Epoch: 1100 Accuracy: 0.589975845410628 Loss: 1.0636508464813232
Epoch: 1200 Accuracy: 0.5902777777777778 Loss: 1.0603208541870117
Epoch: 1300 Accuracy: 0.5902777777777778 Loss: 1.0576958656311035
Epoch: 1400 Accuracy: 0.5884661835748792 Loss: 1.0555980205535889
Epoch: 1500 Accuracy: 0.5878623188405797 Loss: 1.053896427154541
Epoch: 1600 Accuracy: 0.586352657004831 Loss: 1.0524983406066895
Epoch: 1700 Accuracy: 0.5860507246376812 Loss: 1.0513445138931274
Epoch: 1800 Accuracy: 0.5860507246376812 Loss: 1.0503838062286377
Epoch: 1900 Accuracy: 0.5857487922705314 Loss: 1.0495762825012207
--start testing...
run performace metrics: 
              precision    recall  f1-score   support

           0       0.53      0.43      0.48       200
           1       0.57      0.69      0.63       200
           2       0.57      0.68      0.62       200
           3       0.54      0.58      0.56       200
           4       0.45      0.23      0.31       200
           5       0.55      0.67      0.60       200

    accuracy                           0.55      1200
   macro avg       0.54      0.55      0.53      1200
weighted avg       0.54      0.55      0.53      1200

saving models...
Accurarcy is: 54.666666666666664%
