Loading citeseer dataset...
Unique labels [0 1 2 3 4 5]
The index train: [2993, 1795, 2953, 2020, 1513, 913, 1876, 1366, 3158, 1162, 3163, 782, 2313, 1625, 2459, 1271, 1512, 3274, 2923, 1367, 3238, 3086, 2115, 1533, 2503, 2325, 2650, 867, 423, 1101, 1311, 2216, 2557, 2323, 2476, 2106, 12, 3261, 1411, 1067, 1330, 372, 2400, 2482, 1226, 2865, 2521, 554, 34, 977, 2120, 155, 178, 227, 2947, 2577, 655, 777, 1678, 2779, 109, 2229, 855, 45, 203, 2334, 734, 146, 494, 514, 2379, 2454, 970, 339, 1020, 872, 2484, 131, 385, 2921, 1754, 2546, 3256, 97, 1694, 113, 2504, 1112, 4, 2094, 1134, 1030, 2713, 1952, 2879, 2806, 1858, 1462, 2345, 1504, 1886, 2418, 195, 381, 1739, 61, 2414, 1461, 1243, 1645, 2402, 1811, 2834, 1706, 1834, 309, 3047, 1530, 3243, 3031] and index test: [1778, 1591, 29, 3220, 1438, 693, 561, 3298, 1803, 272, 2173, 1610, 3304, 1680, 881, 1973, 1780, 1359, 3029, 3196, 1666, 1516, 1360, 83, 2477, 3040, 56, 2924, 2132, 1759, 1187, 3189, 798, 2644, 1681, 2467, 1027, 891, 2247, 1968, 823, 3067, 2623, 274, 801, 1312, 2176, 2437, 3270, 407, 2378, 1510, 3205, 862, 2170, 2917, 664, 832, 1594, 1743, 1561, 90, 3283, 884, 2081, 3308, 833, 2631, 1059, 1744, 1318, 3093, 2327, 1728, 1039, 1721, 1315, 1168, 3213, 78, 1195, 2156, 2581, 1816, 3273, 2311, 886, 1278, 1486, 2979, 2211, 2468, 1091, 3188, 1057, 2174, 2077, 2027, 1143, 1254, 831, 2560, 1697, 2130, 1370, 1408, 1145, 2183, 813, 963, 1810, 769, 130, 3072, 1627, 897, 2788, 1085, 2207, 2303, 285, 17, 3294, 1823, 2043, 2177, 1923, 1665, 191, 3103, 1082, 909, 1716, 3064, 172, 1399, 1957, 1179, 1767, 1734, 3074, 2131, 2141, 2777, 3284, 2275, 553, 3041, 474, 991, 2103, 1055, 2040, 3311, 2690, 2457, 1931, 2202, 1873, 2265, 1658, 2656, 770, 2607, 2898, 1738, 1409, 1378, 1657, 1204, 1118, 2397, 2643, 1372, 2404, 2380, 2599, 1710, 1637, 2702, 2159, 3125, 2593, 1072, 1483, 1171, 2015, 74, 2942, 175, 1342, 2527, 562, 2769, 2802, 2512, 3230, 1905, 498, 2848, 1417, 1661, 2621, 3210, 1611, 2955, 1531, 2995, 164, 1142, 2059, 2957, 3091, 1248, 2729, 1600, 2222, 1720, 1255, 2299, 2169, 1286, 2047, 2583, 2231, 2252, 2964, 2244, 3079, 1688, 2505, 2193, 3268, 512, 2714, 1690, 2733, 2201, 2937, 1984, 1911, 784, 677, 2257, 2687, 2125, 1562, 1687, 2213, 781, 2626, 2579, 1105, 1607, 1449, 2447, 1647, 128, 149, 2333, 117, 1242, 441, 1016, 1762, 2536, 352, 1775, 2900, 2661, 1088, 917, 2105, 2742, 2688, 1037, 2221, 1902, 2295, 1818, 3173, 1196, 1679, 3001, 2478, 1058, 2654, 2674, 3018, 3053, 1256, 1927, 1173, 461, 1494, 947, 2270, 518, 756, 1525, 301, 2948, 2772, 2165, 1046, 626, 1320, 1100, 120, 3077, 1466, 3171, 3141, 3272, 2861, 3299, 1632, 2971, 1990, 1176, 2609, 1362, 552, 2603, 3161, 578, 1048, 1695, 1673, 2704, 1630, 2409, 1924, 3239, 1860, 3179, 2659, 2206, 2959, 2681, 2304, 2534, 2184, 2612, 375, 1078, 2830, 1392, 1029, 1623, 1390, 2456, 1894, 1425, 1756, 2228, 2264, 2580, 1547, 1573, 2390, 1773, 1537, 3260, 73, 1146, 1639, 324, 2451, 2223, 1847, 1620, 1060, 2522, 3293, 2217, 3159, 2343, 2022, 1416, 1402, 2696, 1117, 1987, 1636, 3310, 1930, 2990, 2566, 1180, 1132, 2749, 2335, 1551, 3237, 1086, 1613, 1693, 702, 2051, 2514, 254, 952, 665, 1586, 2293, 1781, 706, 1568, 1740, 304, 1796, 576, 1022, 1284, 100, 2017, 571, 406, 922, 2460, 3115, 597, 1281, 299, 335, 275, 2361, 2767, 1231, 2427, 3129, 212, 3217, 2466, 228, 2812, 2188, 483, 122, 507, 2246, 803, 3191, 992, 2068, 3058, 234, 1806, 842, 2118, 1699, 2918, 2845, 2064, 2044, 717, 918, 1938, 539, 471, 118, 1004, 95, 800, 2706, 1283, 987, 804, 265, 2815, 233, 440, 2679, 184, 2693, 460, 3280, 967, 455, 1517, 332, 2871, 66, 1264, 748, 3015, 1290, 291, 746, 1969, 428, 51, 914, 684, 1471, 1999, 2464, 839, 1191, 2976, 883, 1247, 680, 1521, 906, 438, 2902, 366, 445, 646, 2480, 535, 1891, 2154, 1334, 1007, 2453, 2016, 3309, 640, 903, 1511, 2868, 349, 180, 408, 356, 470, 683, 1351, 2907, 342, 482, 3017, 391, 1949, 1167, 572, 7, 318, 1649, 2384, 673, 1752, 2525, 1718, 257, 1169, 3009, 419, 251, 2740, 3035, 1410, 574, 456, 1644, 2694, 904, 1199, 2473, 105, 2795, 310, 365, 2817, 1761, 1543, 1322, 608, 1197, 462, 1899, 292, 2809, 392, 1807, 1998, 2810, 2298, 1664, 812, 437, 2914, 698, 1131, 1883, 1852, 2342, 1829, 697, 420, 727, 2149, 2513, 2732, 921, 711, 799, 691, 2790, 2705, 1722, 340, 121, 1211, 651, 163, 941, 526, 3020, 989, 994, 2383, 2851, 64, 676, 3049, 42, 3203, 52, 2839, 892, 2288, 1003, 2985, 2648, 226, 663, 495, 133, 735, 2666, 3057, 973, 1032, 733, 115, 641, 529, 170, 2869, 2285, 808, 76, 2884, 2357, 99, 411, 955, 313, 312, 229, 661, 1888, 386, 2386, 1933, 125, 2646, 40, 2540, 242, 995, 2727, 373, 1024, 1126, 1770, 659, 605, 584, 861, 3033, 1287, 942, 624, 569, 1652, 1576, 368, 346, 2348, 3170, 2554, 2615, 3262, 806, 986, 314, 2984, 1233, 667, 907, 44, 114, 264, 334, 11, 247, 625, 822, 509, 854, 454, 165, 75, 500, 252, 208, 145, 1843, 2987, 1936, 2341, 488, 2996, 401, 703, 2239, 1848, 2226, 492, 1520, 2906, 1983, 84, 630, 675, 246, 347, 631, 2716, 817, 199, 426, 2920, 692, 1621, 965, 885, 2605, 351, 837, 484, 962, 2137, 656, 504, 245, 794, 92, 142, 2532, 70, 950, 3126, 496, 750, 239, 1868, 726, 650, 564, 792, 41, 3155, 20, 202, 2986, 367, 520, 721, 3104, 975, 2429, 448, 1887, 848, 847, 258, 2354, 2771, 2038, 472, 643, 434, 19, 2617, 1205, 866, 2813, 613, 511, 493, 2219, 193, 2734, 536, 912, 2635, 723, 577, 3164, 1356, 890, 1535, 644, 2284, 2191, 1746, 2410, 1992, 3065, 2825, 696, 2930, 2499, 3043, 1348, 87, 1384, 2498, 1476, 2969, 826, 329, 2637, 540, 3113, 1044, 1412, 2766, 838, 1160, 1977, 2198, 2013, 3036, 1355, 2928, 1862, 2723, 1297, 2430, 1074, 3142, 3212, 3111, 2462, 431, 2856, 2997, 2757, 2142, 1368, 948, 1577, 2186, 2811, 2545, 1193, 3184, 1559, 739, 966, 1025, 2991, 2083, 615, 1237, 283, 2365, 1386, 614, 298, 290, 2182, 2272, 1564, 36, 2697, 1560, 1379, 949, 1181, 2479, 263, 1260, 280, 916, 544, 201, 2843, 3266, 2651, 940, 985, 1431, 2143, 3157, 3139, 1859, 124, 2516, 3285, 652, 1120, 2568, 2925, 2962, 1534, 2233, 1104, 2894, 2129, 2395, 63, 2782, 2029, 1213, 1692, 2591, 2302, 2028, 294, 1757, 1729, 2653, 395, 289, 273, 3016, 8, 1514, 3105, 724, 1414, 2562, 2994, 889, 328, 2517, 3275, 3002, 330, 1459, 2807, 1415, 2318, 1400, 2331, 2144, 3241, 789, 3242, 3117, 3087, 2197, 2725, 270, 2565, 140, 627, 3066, 3198, 3076, 3061, 1913, 1800, 2563, 2622, 2973, 2551, 2448, 288, 3063, 2972, 3112, 1017, 3234, 2855, 2641, 2281, 2524, 269, 217, 3062, 134, 1981, 2989, 528, 2249, 1489, 2471, 2636, 173, 1874, 5, 3133, 2678, 2966, 2025, 2145, 2573, 2039, 3123, 2381, 2109, 2080, 3178, 1124, 1215, 2055, 2287, 1188, 1774, 1901, 1341, 1994, 1436, 1918, 2965, 1308, 1580, 3056, 565, 396, 2127, 1877, 1217, 2148, 2518, 1846, 1276, 1964, 2413, 1878, 1906, 2750, 1974, 1960, 1900, 1772, 1377, 2775, 225, 2569, 851, 1361, 1926, 3138, 1448, 2048, 1338, 2063, 413, 3039, 1423, 2863, 2739, 2859, 1785, 135, 2060, 3055, 3094, 1835, 2630, 1704, 2461, 2346, 3118, 2398, 2425, 1827, 1306, 1465, 1299, 2741, 2412, 1549, 2785, 3259, 1837, 432, 1708, 1683, 766, 1784, 2175, 2664, 1202, 1470, 2396, 3070, 1589, 1890, 3265, 2916, 1540, 818, 2836, 2121, 3032, 1831, 681, 2756, 2718, 1422, 1805, 2099, 2439, 705, 2857, 716, 2820, 207, 2336, 2072, 2828, 908, 1871, 2963, 2933, 2553, 3059, 3005, 1258, 2671, 2112, 3004, 3101, 1648, 810, 1839, 2338, 795, 1841, 926, 169, 1655, 2968, 2754, 1502, 2296, 1838, 3006, 1303, 1300, 2190, 1064, 2062, 1045, 1541, 2752, 343, 1519, 1955, 1571, 1270, 1151, 2050, 2124, 2049, 2005, 249, 1185, 1853, 2023, 1285, 3010, 1113, 433, 1446, 559, 1940, 2255, 3219, 1764, 2095, 2862, 3127, 2796, 2382, 1603, 1453, 2440, 1292, 2151, 1705, 1108, 2515, 2075, 610, 1435, 1702, 2870, 695]
method running...
--network status--
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Method_Classification                    [3312, 6]                 --
├─Sequential_8b872f: 1-1                 [3312, 6]                 --
│    └─GCNConv: 2-1                      [3312, 50]                50
│    │    └─Linear: 3-1                  [3312, 50]                185,150
│    │    └─SumAggregation: 3-2          [3312, 50]                --
│    └─ReLU: 2-2                         [3312, 50]                --
│    └─GCNConv: 2-3                      [3312, 6]                 6
│    │    └─Linear: 3-3                  [3312, 6]                 300
│    │    └─SumAggregation: 3-4          [3312, 6]                 --
│    └─Sigmoid: 2-4                      [3312, 6]                 --
==========================================================================================
Total params: 185,506
Trainable params: 185,506
Non-trainable params: 0
Total mult-adds (M): 614.21
==========================================================================================
Input size (MB): 49.13
Forward/backward pass size (MB): 1.48
Params size (MB): 0.74
Estimated Total Size (MB): 51.36
==========================================================================================
--start training...
Epoch: 0 Accuracy: 0.1503623188405797 Loss: 1.7939592599868774
Epoch: 100 Accuracy: 0.5108695652173914 Loss: 1.5636132955551147
Epoch: 200 Accuracy: 0.5733695652173914 Loss: 1.3538777828216553
Epoch: 300 Accuracy: 0.591183574879227 Loss: 1.2352451086044312
Epoch: 400 Accuracy: 0.5984299516908212 Loss: 1.1689156293869019
Epoch: 500 Accuracy: 0.5969202898550725 Loss: 1.1305650472640991
Epoch: 600 Accuracy: 0.5978260869565217 Loss: 1.1069064140319824
Epoch: 700 Accuracy: 0.5972222222222222 Loss: 1.0916157960891724
Epoch: 800 Accuracy: 0.596316425120773 Loss: 1.0811488628387451
Epoch: 900 Accuracy: 0.5948067632850241 Loss: 1.073599934577942
Epoch: 1000 Accuracy: 0.5926932367149759 Loss: 1.0679452419281006
Epoch: 1100 Accuracy: 0.589975845410628 Loss: 1.0636508464813232
Epoch: 1200 Accuracy: 0.5902777777777778 Loss: 1.0603208541870117
Epoch: 1300 Accuracy: 0.5902777777777778 Loss: 1.0576958656311035
Epoch: 1400 Accuracy: 0.5884661835748792 Loss: 1.0555980205535889
Epoch: 1500 Accuracy: 0.5878623188405797 Loss: 1.053896427154541
Epoch: 1600 Accuracy: 0.586352657004831 Loss: 1.0524983406066895
Epoch: 1700 Accuracy: 0.5860507246376812 Loss: 1.0513445138931274
Epoch: 1800 Accuracy: 0.5860507246376812 Loss: 1.0503838062286377
Epoch: 1900 Accuracy: 0.5857487922705314 Loss: 1.0495762825012207
--start testing...
run performace metrics: 
              precision    recall  f1-score   support

           0       0.53      0.43      0.48       200
           1       0.57      0.69      0.63       200
           2       0.57      0.68      0.62       200
           3       0.54      0.58      0.56       200
           4       0.45      0.23      0.31       200
           5       0.55      0.67      0.60       200

    accuracy                           0.55      1200
   macro avg       0.54      0.55      0.53      1200
weighted avg       0.54      0.55      0.53      1200

saving models...
Accurarcy is: 54.666666666666664%
Loading citeseer dataset...
Unique labels [0 1 2 3 4 5]
The index train: [3238, 1210, 552, 3052, 2913, 2139, 2733, 3192, 1851, 1984, 1802, 2759, 3183, 1902, 1107, 1679, 1106, 867, 917, 1818, 952, 1592, 2064, 2670, 910, 555, 2161, 539, 2427, 253, 2686, 1257, 58, 3022, 2633, 156, 827, 391, 2780, 1454, 2754, 3259, 1045, 2886, 705, 2518, 1926, 2755, 1846, 2048, 1683, 2862, 1214, 1578, 1266, 2000, 2569, 1453, 969, 2413, 2591, 3111, 2197, 97, 2129, 1414, 1379, 2196, 1862, 288, 2725, 3113, 2928, 3234, 2479, 1134, 2855, 290, 3285, 2281, 360, 2606, 255, 2851, 499, 196, 836, 2312, 3146, 1868, 163, 416, 595, 1233, 187, 346, 192, 1566, 519, 19, 2777, 96, 1942, 1810, 3007, 2702, 1946, 1640, 1483, 831, 997, 2433, 2076, 1643, 1625, 1627, 2027, 2481, 31, 1227] and index test: [2489, 2561, 2164, 1294, 2407, 1613, 783, 2228, 3141, 3091, 1866, 2587, 1119, 765, 3207, 2661, 1076, 2234, 1894, 2217, 1532, 2223, 3044, 3143, 784, 2642, 1390, 2523, 2749, 3132, 2058, 2878, 2125, 1939, 2350, 2511, 2556, 1466, 1180, 73, 677, 2483, 1494, 2335, 1573, 1048, 1813, 352, 3267, 1403, 3302, 2041, 1141, 2253, 556, 2572, 2101, 1416, 781, 14, 1499, 1924, 3237, 3299, 1828, 1148, 1081, 1707, 1425, 2534, 1023, 2992, 1634, 972, 1117, 2476, 637, 1173, 331, 743, 1255, 2624, 441, 2939, 756, 1620, 1684, 1417, 2184, 1801, 2236, 1439, 1556, 2011, 702, 2119, 512, 2899, 1109, 378, 2456, 1393, 55, 1037, 1776, 1480, 1723, 3258, 2758, 2053, 1830, 2710, 1914, 384, 1047, 1544, 578, 1769, 2567, 308, 1362, 1225, 2625, 1646, 1958, 1049, 878, 518, 3307, 3046, 2307, 2415, 1562, 1537, 3086, 149, 2578, 1864, 2251, 1473, 638, 2220, 2057, 327, 1442, 1967, 1885, 1860, 2609, 2995, 2657, 1909, 1261, 1500, 2674, 3030, 2602, 1427, 1623, 1289, 3144, 1206, 1673, 3292, 2503, 1912, 1932, 2193, 1041, 1060, 3001, 1701, 1604, 1001, 57, 971, 2595, 2765, 2584, 2046, 1990, 1426, 1132, 326, 423, 421, 774, 1236, 2957, 2946, 709, 80, 2603, 2712, 1268, 3247, 1959, 1538, 1687, 2222, 256, 182, 1349, 717, 2466, 3008, 1131, 1383, 523, 2259, 2738, 1322, 2793, 2364, 738, 231, 977, 547, 2188, 598, 2399, 189, 844, 619, 2521, 106, 3014, 2564, 805, 1741, 525, 999, 698, 1239, 2945, 336, 903, 257, 1999, 69, 921, 1788, 3208, 2763, 669, 602, 1667, 2181, 3252, 223, 503, 1807, 2694, 299, 157, 3015, 694, 597, 48, 2744, 3181, 2024, 804, 94, 2446, 1821, 1593, 1474, 420, 332, 2460, 2453, 1752, 153, 1898, 708, 639, 2104, 1718, 992, 2588, 3236, 1267, 213, 2767, 2154, 79, 2634, 580, 777, 2359, 227, 2018, 28, 1283, 1247, 771, 1829, 2926, 517, 1678, 573, 216, 2976, 2791, 746, 2814, 85, 2663, 1249, 3217, 2795, 127, 1430, 1799, 3309, 1005, 1290, 2902, 699, 7, 261, 668, 3248, 2068, 2097, 476, 3135, 483, 244, 2693, 1075, 1766, 648, 2858, 414, 558, 727, 829, 317, 1471, 772, 658, 906, 1199, 905, 549, 3000, 3023, 2548, 212, 3301, 590, 2740, 455, 2778, 581, 291, 427, 522, 888, 2815, 819, 444, 2907, 876, 1008, 2528, 440, 1334, 1998, 1073, 2874, 2574, 1796, 1899, 557, 1000, 1336, 1852, 65, 66, 1649, 471, 100, 1895, 3289, 749, 510, 105, 2464, 673, 2480, 1628, 799, 685, 1282, 1387, 234, 2679, 2963, 1713, 2099, 2966, 1031, 2870, 1183, 1703, 1337, 2432, 559, 3219, 195, 415, 1341, 657, 1870, 2426, 1178, 1151, 2382, 852, 3006, 1669, 3177, 1113, 563, 1648, 343, 1838, 2052, 2776, 820, 1994, 1541, 2882, 2004, 2592, 1889, 653, 2796, 1925, 2756, 1676, 1259, 1198, 2009, 2402, 1706, 1755, 3032, 2368, 1457, 1361, 1805, 2080, 2025, 2718, 2664, 3118, 1708, 961, 2381, 2190, 715, 662, 2889, 1280, 1333, 944, 1612, 3095, 3133, 2279, 433, 2060, 1252, 1224, 53, 1218, 1712, 2063, 1901, 3070, 2387, 2800, 1900, 2411, 1124, 1878, 1332, 2376, 1097, 1841, 1303, 1827, 766, 3101, 1434, 2820, 635, 1235, 1719, 3094, 2002, 2828, 1820, 2122, 1215, 1270, 2798, 1377, 1501, 2965, 2243, 2039, 2968, 1185, 1785, 3084, 1886, 2148, 1765, 2075, 1836, 2857, 1929, 2537, 1306, 2887, 1503, 3010, 2398, 2610, 2023, 1711, 161, 810, 1202, 2003, 3102, 2472, 2418, 1540, 309, 2062, 396, 2127, 926, 1955, 1487, 3227, 1502, 2123, 1705, 9, 2981, 2576, 135, 1617, 1232, 2405, 359, 2630, 1582, 1325, 2109, 413, 1819, 1158, 1890, 1338, 466, 1293, 1096, 1465, 1811, 1300, 2933, 3031, 2838, 2458, 3038, 2055, 1542, 3131, 853, 1698, 1571, 1980, 3265, 1276, 1346, 491, 1421, 3045, 3106, 2001, 1324, 1572, 591, 263, 3112, 2962, 2186, 2249, 2636, 328, 2365, 3241, 3139, 1965, 1791, 2545, 1534, 2013, 2498, 2345, 294, 2563, 2284, 2613, 87, 890, 3036, 985, 1358, 8, 124, 2144, 3076, 2757, 1560, 3184, 1858, 1030, 134, 1859, 2991, 2641, 2395, 2766, 528, 2562, 1746, 3117, 1355, 3212, 1754, 2198, 217, 1193, 940, 2723, 2622, 289, 2517, 1489, 1800, 36, 2568, 1260, 1577, 1348, 1514, 173, 3164, 3061, 1692, 1220, 1074, 2994, 2635, 2969, 1459, 3060, 2989, 2353, 838, 916, 2797, 2811, 2825, 273, 2430, 540, 1154, 789, 2973, 1213, 1443, 2731, 1638, 3198, 2697, 2462, 269, 1368, 2879, 395, 1237, 2318, 1431, 2182, 948, 1112, 544, 2843, 1400, 2930, 1564, 1504, 2178, 2029, 1386, 2925, 2539, 1981, 2929, 912, 2856, 2317, 2028, 3002, 615, 627, 2448, 889, 1993, 723, 2471, 3266, 3063, 1017, 577, 3066, 2637, 330, 3157, 2653, 3065, 2997, 3087, 1857, 2302, 1729, 2143, 3025, 2410, 949, 724, 1913, 856, 2565, 2504, 1694, 1952, 2972, 2806, 1104, 966, 2713, 2546, 3242, 280, 2142, 4, 1654, 1476, 1297, 2807, 1462, 1356, 3016, 1874, 2805, 126, 2191, 431, 826, 2331, 739, 2501, 2651, 2894, 2524, 2782, 63, 2499, 1120, 329, 1415, 1977, 2272, 1181, 2083, 1384, 2998, 3105, 1757, 101, 426, 1420, 663, 794, 3096, 484, 846, 2840, 2615, 631, 2117, 1020, 92, 877, 3107, 344, 1935, 2813, 583, 2575, 630, 373, 2354, 132, 970, 939, 2012, 351, 666, 607, 1413, 1065, 2290, 585, 2185, 861, 625, 3290, 548, 1010, 2421, 2554, 2469, 125, 146, 731, 2229, 1003, 3185, 2727, 400, 109, 3104, 64, 2987, 211, 885, 472, 241, 955, 2703, 2208, 193, 964, 141, 778, 847, 2617, 1477, 504, 142, 865, 3269, 2487, 2379, 33, 2383, 115, 1216, 2086, 1240, 486, 643, 758, 923, 282, 250, 340, 2078, 606, 1211, 1675, 11, 816, 943, 611, 942, 0, 188, 43, 996, 2438, 605, 980, 790, 988, 2771, 2921, 3151, 2341, 59, 46, 530, 2351, 726, 3180, 121, 229, 654, 3020, 72, 487, 792, 509, 729, 848, 467, 230, 959, 3150, 1844, 131, 2608, 564, 536, 973, 436, 45, 982, 3203, 531, 488, 3277, 2441, 735, 750, 788, 1437, 52, 529, 495, 2531, 158, 2790, 962, 454, 650, 42, 1520, 38, 2543, 497, 89, 2348, 1024, 806, 808, 815, 2282, 3281, 239, 386, 3168, 868, 936, 3170, 919, 333, 339, 464, 3114, 198, 984, 345, 2465, 1843, 526, 864, 569, 520, 2684, 409, 2285, 2357, 203, 2822, 312, 2089, 817, 56, 3251, 2927, 3197, 1941, 1153, 1091, 1099, 2680, 534, 2915, 2980, 2768, 859, 2329, 2643, 2366, 2131, 2728, 993, 1876, 1653, 2656, 2898, 215, 191, 1059, 274, 2495, 1166, 3041, 2202, 1742, 1110, 1438, 1139, 1278, 2655, 2172, 1375, 1319, 2953, 3297, 1629, 1700, 782, 3216, 1365, 2103, 3196, 29, 2420, 1972, 1768, 833, 102, 78, 2132, 2116, 2077, 1323, 3088, 268, 1975, 3304, 1288, 2787, 2769, 2303, 1822, 2416, 2629, 3067, 1657, 297, 1085, 991, 1596, 3085, 162, 3099, 3254, 1208, 2979, 2313, 1816, 1855, 1369, 1624, 1619, 2751, 3213, 1641, 2988, 1033, 1269, 2419, 284, 2975, 2993, 2640, 1327, 2477, 1451, 3211, 1370, 1406, 172, 3244, 1372, 2923, 1873, 1710, 823, 2007, 1823, 1973, 2639, 1780, 1947, 1187, 159, 1731, 2156, 305, 895, 77, 1123, 537, 2375, 1399, 1689, 2560, 1968, 909, 2675, 2470, 2019, 3029, 2685, 1957, 1978, 2866, 1168, 561, 3274, 1595, 1824, 2397, 2904, 2324, 1594, 1050, 1759, 1156, 262, 2160, 1666, 664, 1179, 1245, 32, 1315, 2695, 2527, 2014, 2875, 1697, 1920, 2277, 2275, 2082, 3071, 1557, 1495, 1985, 3040, 2764, 3250, 2512, 1143, 1363, 1274, 1637, 1963, 505, 2867, 2070, 963, 533, 2708, 2593, 1039, 123, 2026, 1350, 3093, 3218, 2174, 2743]
method running...
--network status--
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Method_Classification                    [3312, 6]                 --
├─Sequential_1b8834: 1-1                 [3312, 6]                 --
│    └─GCNConv: 2-1                      [3312, 50]                50
│    │    └─Linear: 3-1                  [3312, 50]                185,150
│    │    └─SumAggregation: 3-2          [3312, 50]                --
│    └─ReLU: 2-2                         [3312, 50]                --
│    └─GCNConv: 2-3                      [3312, 6]                 6
│    │    └─Linear: 3-3                  [3312, 6]                 300
│    │    └─SumAggregation: 3-4          [3312, 6]                 --
│    └─Sigmoid: 2-4                      [3312, 6]                 --
==========================================================================================
Total params: 185,506
Trainable params: 185,506
Non-trainable params: 0
Total mult-adds (M): 614.21
==========================================================================================
Input size (MB): 49.13
Forward/backward pass size (MB): 1.48
Params size (MB): 0.74
Estimated Total Size (MB): 51.36
==========================================================================================
--start training...
Epoch: 0 Accuracy: 0.2086352657004831 Loss: 1.7926758527755737
Epoch: 100 Accuracy: 0.4821859903381642 Loss: 1.551129937171936
Epoch: 200 Accuracy: 0.5739734299516909 Loss: 1.3443034887313843
Epoch: 300 Accuracy: 0.5960144927536232 Loss: 1.2258328199386597
Epoch: 400 Accuracy: 0.5993357487922706 Loss: 1.1609569787979126
Epoch: 500 Accuracy: 0.6023550724637681 Loss: 1.1238117218017578
Epoch: 600 Accuracy: 0.6020531400966184 Loss: 1.1012934446334839
Epoch: 700 Accuracy: 0.5987318840579711 Loss: 1.0868868827819824
Epoch: 800 Accuracy: 0.5978260869565217 Loss: 1.077197790145874
Epoch: 900 Accuracy: 0.595108695652174 Loss: 1.070405125617981
Epoch: 1000 Accuracy: 0.595108695652174 Loss: 1.065474271774292
Epoch: 1100 Accuracy: 0.5939009661835749 Loss: 1.0618014335632324
Epoch: 1200 Accuracy: 0.5929951690821256 Loss: 1.0590002536773682
Epoch: 1300 Accuracy: 0.592391304347826 Loss: 1.0568196773529053
Epoch: 1400 Accuracy: 0.5932971014492754 Loss: 1.0550918579101562
Epoch: 1500 Accuracy: 0.592391304347826 Loss: 1.053702473640442
Epoch: 1600 Accuracy: 0.5926932367149759 Loss: 1.0525693893432617
Epoch: 1700 Accuracy: 0.5929951690821256 Loss: 1.051634669303894
Epoch: 1800 Accuracy: 0.5929951690821256 Loss: 1.050855278968811
Epoch: 1900 Accuracy: 0.5926932367149759 Loss: 1.0501995086669922
Epoch: 2000 Accuracy: 0.592391304347826 Loss: 1.0496429204940796
Epoch: 2100 Accuracy: 0.5926932367149759 Loss: 1.0491669178009033
Epoch: 2200 Accuracy: 0.5926932367149759 Loss: 1.0487573146820068
Epoch: 2300 Accuracy: 0.5926932367149759 Loss: 1.0484023094177246
Epoch: 2400 Accuracy: 0.5920893719806763 Loss: 1.0480931997299194
Epoch: 2500 Accuracy: 0.591183574879227 Loss: 1.04782235622406
Epoch: 2600 Accuracy: 0.591183574879227 Loss: 1.0475841760635376
Epoch: 2700 Accuracy: 0.591183574879227 Loss: 1.047373652458191
Epoch: 2800 Accuracy: 0.5905797101449275 Loss: 1.0471867322921753
Epoch: 2900 Accuracy: 0.5902777777777778 Loss: 1.047020435333252
--start testing...
run performace metrics: 
              precision    recall  f1-score   support

           0       0.66      0.58      0.62       200
           1       0.49      0.77      0.60       200
           2       0.68      0.65      0.67       200
           3       0.35      0.26      0.30       200
           4       0.59      0.68      0.63       200
           5       0.55      0.40      0.46       200

    accuracy                           0.56      1200
   macro avg       0.55      0.55      0.55      1200
weighted avg       0.55      0.56      0.55      1200

saving models...
Accurarcy is: 55.50000000000001%
Loading citeseer dataset...
Unique labels [0 1 2 3 4 5]
The index train: [1334, 516, 2097, 2385, 903, 1335, 1061, 636, 2403, 299, 261, 842, 1290, 699, 680, 223, 205, 2858, 998, 507, 3036, 2448, 2499, 2284, 431, 1044, 1965, 1913, 290, 652, 2997, 1297, 3002, 1104, 2462, 3061, 1729, 1415, 1862, 1559, 2590, 2283, 1602, 2417, 2223, 3046, 3258, 878, 2222, 2304, 164, 2990, 2059, 3132, 1776, 2286, 2295, 2155, 2587, 168, 2006, 2550, 1656, 3123, 3257, 3152, 3094, 1519, 2381, 2145, 2008, 1218, 3225, 1925, 3120, 1198, 2376, 1890, 2707, 2820, 2341, 163, 3155, 631, 2229, 2936, 3050, 2770, 726, 736, 2434, 2648, 2717, 0, 373, 2089, 792, 935, 2348, 1567, 1625, 2690, 2202, 96, 1595, 2979, 2116, 2988, 1624, 479, 2794, 274, 833, 1780, 3306, 1372, 1873, 2494, 31, 1407] and index test: [365, 2907, 1331, 1229, 3028, 3078, 812, 3280, 2363, 253, 3303, 2564, 2066, 456, 459, 336, 236, 952, 37, 3224, 2745, 1165, 105, 2571, 1593, 2031, 3000, 408, 206, 819, 2814, 1267, 254, 2693, 256, 3116, 2740, 1231, 1283, 574, 535, 419, 10, 538, 2104, 3289, 3012, 999, 220, 451, 103, 233, 958, 2064, 157, 234, 1238, 575, 2364, 3217, 1956, 560, 2482, 227, 2926, 182, 481, 1351, 152, 2359, 1008, 22, 2976, 3300, 673, 3181, 445, 1219, 1155, 3014, 291, 2018, 914, 2633, 2983, 3121, 2065, 154, 602, 364, 2871, 212, 1062, 2214, 921, 447, 698, 797, 88, 669, 1004, 655, 1829, 2118, 366, 906, 265, 189, 1938, 2496, 2408, 2548, 683, 66, 744, 1628, 2872, 221, 475, 1284, 100, 525, 1169, 686, 3191, 1650, 557, 1807, 2570, 1937, 1241, 2466, 2880, 670, 3015, 2854, 2780, 1660, 2128, 2120, 1471, 355, 390, 2865, 1526, 2044, 2507, 24, 296, 2298, 1313, 2706, 1279, 1244, 742, 468, 2400, 156, 155, 244, 541, 711, 2778, 228, 48, 2809, 2525, 2450, 779, 1230, 1209, 902, 1553, 566, 1766, 1678, 267, 1753, 1222, 1788, 257, 85, 791, 1322, 684, 828, 3153, 977, 888, 460, 953, 107, 694, 777, 34, 82, 929, 2793, 3208, 3145, 3242, 3016, 2191, 2471, 1154, 2894, 3142, 2178, 1694, 2517, 2196, 124, 1412, 985, 1859, 644, 280, 173, 724, 1414, 2028, 1514, 1992, 2182, 2565, 3065, 2144, 614, 1857, 217, 1981, 3117, 3266, 270, 3198, 1025, 2083, 2856, 2094, 2568, 2546, 97, 2930, 1193, 2972, 2545, 1348, 5, 329, 201, 2233, 1560, 2302, 3043, 1476, 591, 2731, 3076, 838, 2989, 2879, 2641, 2991, 1220, 2697, 739, 2713, 856, 3113, 3139, 1431, 2524, 2806, 2653, 1181, 2410, 288, 2501, 696, 2613, 2345, 3060, 283, 273, 2249, 1030, 2563, 2635, 1462, 2969, 3285, 1504, 1134, 294, 3063, 2013, 1638, 2637, 113, 263, 2551, 3157, 2962, 1356, 3234, 2782, 1952, 1757, 3111, 723, 1993, 3275, 2843, 2622, 1160, 1384, 269, 1237, 2186, 2129, 330, 2516, 1358, 2651, 1692, 2929, 2318, 912, 1443, 1355, 3062, 3112, 2928, 2539, 615, 1577, 1260, 1120, 2198, 2723, 2331, 3087, 1791, 2725, 966, 2825, 940, 140, 889, 1977, 2805, 3164, 2498, 2365, 627, 1213, 2811, 1459, 544, 528, 1800, 36, 2562, 890, 4, 1754, 1353, 2994, 3241, 1379, 2504, 916, 289, 2636, 8, 1564, 2142, 1489, 3105, 87, 948, 2317, 2029, 1535, 1654, 1534, 3212, 3184, 2998, 328, 1017, 1400, 1074, 298, 1386, 134, 2591, 2281, 1112, 1874, 3272, 2652, 1013, 2010, 1117, 2037, 1537, 2409, 1029, 2101, 2352, 3144, 1532, 327, 1404, 1607, 2831, 331, 2184, 2333, 2256, 2034, 2203, 1242, 2125, 2115, 421, 1041, 1875, 1562, 702, 756, 2688, 1253, 2609, 301, 2624, 353, 3310, 1620, 2140, 1786, 1307, 1894, 2561, 588, 3192, 2672, 1695, 1775, 325, 2093, 629, 1914, 743, 2165, 450, 1401, 1122, 376, 2350, 3143, 2899, 1089, 972, 1932, 2620, 3021, 1616, 1851, 1544, 2535, 1882, 2657, 2206, 2595, 556, 2332, 1405, 3201, 3052, 2704, 2220, 1295, 2228, 2057, 1509, 1630, 3026, 1439, 2500, 1450, 512, 362, 2621, 2505, 2168, 2108, 1028, 1939, 1170, 1847, 1525, 2789, 2422, 2954, 3260, 1200, 1864, 2167, 1043, 774, 1048, 3305, 2325, 2665, 2736, 2163, 2045, 2572, 518, 781, 2307, 1725, 2257, 2476, 2423, 2248, 1088, 1622, 1426, 3160, 3293, 2971, 2415, 2231, 2235, 1573, 1403, 1915, 710, 1402, 1546, 1133, 14, 679, 3268, 2821, 1466, 2058, 1302, 2689, 1081, 1352, 638, 1751, 1790, 1545, 1086, 2201, 1190, 2319, 2306, 3080, 1990, 2485, 1347, 2339, 1090, 2036, 1246, 1507, 2138, 2388, 3024, 1001, 3292, 1988, 2712, 1614, 1673, 1294, 1813, 1248, 375, 1613, 2602, 441, 2245, 2958, 1685, 2724, 1485, 2205, 1038, 1707, 1885, 1228, 1067, 2102, 1436, 2755, 1945, 433, 2458, 1469, 1889, 1784, 1280, 3186, 3084, 1839, 2321, 2549, 1361, 3047, 1266, 1094, 1292, 870, 3227, 293, 1252, 1128, 766, 1578, 2576, 135, 2747, 1670, 1617, 1422, 563, 2741, 1820, 3119, 961, 1423, 2338, 1503, 2099, 1232, 2864, 1827, 3097, 2113, 1917, 1382, 2775, 2292, 2254, 2382, 1341, 2518, 1603, 1674, 1612, 1270, 2405, 1906, 1918, 1432, 1749, 1698, 927, 2752, 2784, 1045, 818, 2439, 1589, 1434, 1151, 381, 3243, 2055, 2060, 2121, 2005, 1221, 968, 3010, 1461, 2387, 1900, 225, 2966, 1929, 1846, 2080, 2279, 915, 2785, 1669, 1418, 1960, 2897, 1953, 2358, 2592, 1518, 705, 810, 1712, 2002, 1853, 343, 2098, 3101, 2428, 1811, 3042, 2023, 1285, 1760, 1377, 1618, 1572, 2052, 2916, 543, 2418, 3059, 2461, 1994, 1448, 1337, 1178, 1676, 1886, 1317, 2054, 795, 2860, 2063, 1333, 2426, 2735, 582, 3265, 3039, 2347, 2001, 1325, 657, 1550, 2826, 2412, 1861, 2049, 2175, 1871, 2798, 3106, 3081, 3178, 1870, 1831, 2148, 1291, 2413, 1265, 3100, 2886, 1463, 851, 662, 3182, 715, 3138, 2999, 1501, 1263, 1303, 1805, 3118, 2610, 852, 2273, 1530, 1916, 2859, 1344, 9, 1980, 1214, 2432, 1739, 2025, 2039, 2425, 1837, 1299, 2968, 195, 1421, 465, 704, 1453, 681, 2438, 486, 943, 885, 132, 1343, 735, 101, 807, 548, 611, 2012, 874, 3126, 19, 2851, 1758, 529, 663, 509, 92, 759, 426, 778, 351, 750, 2357, 196, 2908, 942, 2078, 400, 340, 255, 2454, 1848, 3281, 984, 472, 2909, 2441, 211, 2391, 416, 241, 2615, 865, 360, 344, 3240, 187, 678, 720, 125, 146, 760, 519, 2239, 2698, 192, 817, 2484, 109, 3203, 64, 536, 504, 675, 346, 2896, 2444, 959, 2850, 43, 193, 995, 141, 814, 996, 835, 625, 2684, 142, 2771, 237, 487, 2666, 794, 33, 2840, 115, 1722, 3290, 2619, 936, 436, 788, 815, 418, 282, 250, 3075, 647, 666, 955, 583, 11, 2386, 2606, 654, 822, 980, 188, 281, 643, 1020, 1079, 1216, 3104, 731, 2533, 59, 46, 1621, 2543, 816, 497, 121, 229, 3147, 3151, 72, 2449, 796, 564, 758, 877, 499, 230, 403, 872, 2986, 808, 923, 131, 2232, 605, 467, 1003, 488, 45, 1032, 111, 593, 495, 1879, 962, 2605, 3048, 484, 492, 531, 2721, 1868, 52, 846, 530, 2445, 158, 863, 1233, 994, 454, 692, 42, 585, 38, 973, 975, 89, 2540, 1388, 854, 1211, 2996, 2465, 2, 239, 386, 836, 860, 1496, 2290, 945, 333, 339, 595, 464, 1887, 198, 3007, 1759, 993, 2362, 3165, 1594, 2277, 1375, 2781, 1091, 2691, 2629, 3214, 1946, 1904, 56, 1288, 997, 2367, 1700, 782, 1110, 831, 3108, 1710, 2915, 1162, 2508, 1085, 1365, 769, 2927, 1973, 2420, 3071, 2768, 2470, 3092, 1970, 534, 1495, 1947, 2993, 2875, 1099, 3040, 1795, 1269, 1978, 1139, 215, 191, 2313, 1278, 2743, 1153, 2607, 1653, 1369, 1640, 2133, 859, 2088, 2866, 3294, 1557, 2527, 2867, 2096, 3213, 1972, 29, 3090, 1816, 1822, 1996, 1810, 102, 78, 1187, 2173, 2027, 2195, 2680, 3235, 268, 1823, 2160, 1208, 1227, 1619, 2130, 1327, 1824, 2389, 2975, 2433, 1059, 1166, 3099, 2728, 297, 284, 991, 3221, 2132, 162, 3154, 1629, 1451, 1975, 3019, 1033, 1323, 2020, 1744, 3284, 1768, 2702, 172, 2156, 1483, 1643, 2194, 3103, 823, 3085, 1596, 83, 1565, 1319, 2599, 2326, 1971, 2070, 1697, 159, 2209, 2695, 305, 895, 77, 1123, 537, 3196, 2019, 1742, 2655, 1985, 909, 2764, 1398, 3254, 3072, 1399, 1066, 2174, 3311, 1168, 3067, 561, 1931, 2171, 1666, 3125, 1637, 1018, 3041, 3229, 1370, 1050, 2495, 1156, 262, 1438, 2416, 664, 1179, 1245, 32, 1315, 1641, 2769, 2076, 2904, 1731, 1963, 2366, 1406, 1920, 2593, 2026, 1627, 2172, 2030, 3218, 2849, 3197, 2645, 1143]
method running...
--network status--
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Method_Classification                    [3312, 6]                 --
├─Sequential_439f96: 1-1                 [3312, 6]                 --
│    └─GCNConv: 2-1                      [3312, 50]                50
│    │    └─Linear: 3-1                  [3312, 50]                185,150
│    │    └─SumAggregation: 3-2          [3312, 50]                --
│    └─ReLU: 2-2                         [3312, 50]                --
│    └─GCNConv: 2-3                      [3312, 6]                 6
│    │    └─Linear: 3-3                  [3312, 6]                 300
│    │    └─SumAggregation: 3-4          [3312, 6]                 --
│    └─Sigmoid: 2-4                      [3312, 6]                 --
==========================================================================================
Total params: 185,506
Trainable params: 185,506
Non-trainable params: 0
Total mult-adds (M): 614.21
==========================================================================================
Input size (MB): 49.13
Forward/backward pass size (MB): 1.48
Params size (MB): 0.74
Estimated Total Size (MB): 51.36
==========================================================================================
--start training...
Epoch: 0 Accuracy: 0.12892512077294685 Loss: 1.7932753562927246
Epoch: 100 Accuracy: 0.586352657004831 Loss: 1.0674773454666138
Epoch: 200 Accuracy: 0.5775966183574879 Loss: 1.0498976707458496
Epoch: 300 Accuracy: 0.5760869565217391 Loss: 1.0464413166046143
Epoch: 400 Accuracy: 0.5739734299516909 Loss: 1.0452338457107544
Epoch: 500 Accuracy: 0.5733695652173914 Loss: 1.0446646213531494
Epoch: 600 Accuracy: 0.5715579710144928 Loss: 1.0443493127822876
Epoch: 700 Accuracy: 0.5706521739130435 Loss: 1.0441553592681885
Epoch: 800 Accuracy: 0.5700483091787439 Loss: 1.0440272092819214
Epoch: 900 Accuracy: 0.5694444444444444 Loss: 1.0439378023147583
Epoch: 1000 Accuracy: 0.5688405797101449 Loss: 1.0438731908798218
Epoch: 1100 Accuracy: 0.5676328502415459 Loss: 1.0438246726989746
Epoch: 1200 Accuracy: 0.5670289855072463 Loss: 1.0437877178192139
Epoch: 1300 Accuracy: 0.5667270531400966 Loss: 1.043758511543274
Epoch: 1400 Accuracy: 0.5664251207729468 Loss: 1.043735146522522
Epoch: 1500 Accuracy: 0.5670289855072463 Loss: 1.0437161922454834
Epoch: 1600 Accuracy: 0.5661231884057971 Loss: 1.0437006950378418
Epoch: 1700 Accuracy: 0.5667270531400966 Loss: 1.0436875820159912
Epoch: 1800 Accuracy: 0.5661231884057971 Loss: 1.0436768531799316
Epoch: 1900 Accuracy: 0.5661231884057971 Loss: 1.0436674356460571
Epoch: 2000 Accuracy: 0.5658212560386473 Loss: 1.0436594486236572
Epoch: 2100 Accuracy: 0.5652173913043478 Loss: 1.0436526536941528
Epoch: 2200 Accuracy: 0.5655193236714976 Loss: 1.0436465740203857
Epoch: 2300 Accuracy: 0.5655193236714976 Loss: 1.043641448020935
Epoch: 2400 Accuracy: 0.5655193236714976 Loss: 1.0436367988586426
Epoch: 2500 Accuracy: 0.5649154589371981 Loss: 1.0436326265335083
Epoch: 2600 Accuracy: 0.5652173913043478 Loss: 1.0436292886734009
Epoch: 2700 Accuracy: 0.5643115942028986 Loss: 1.0436259508132935
Epoch: 2800 Accuracy: 0.563707729468599 Loss: 1.0436232089996338
Epoch: 2900 Accuracy: 0.563707729468599 Loss: 1.0436204671859741
--start testing...
run performace metrics: 
              precision    recall  f1-score   support

           0       0.46      0.57      0.51       200
           1       0.44      0.25      0.32       200
           2       0.61      0.58      0.60       200
           3       0.64      0.68      0.66       200
           4       0.56      0.69      0.61       200
           5       0.44      0.41      0.43       200

    accuracy                           0.53      1200
   macro avg       0.52      0.53      0.52      1200
weighted avg       0.52      0.53      0.52      1200

saving models...
Accurarcy is: 53.083333333333336%
